{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "charged-procurement",
   "metadata": {},
   "source": [
    "# Einleitung: Der Naive Bayes Klassifikator\n",
    "\n",
    "Der Naive Bayes Klassifikator ist einer der einfachsten Werkzeuge des Maschinellen Lernens, wenn es darum geht, irgendwelche einkommenden Daten zu klassifizieren, z.B.:\n",
    "\n",
    "- Ist eine eingehende eMail eine Spam-Email? (Klassifizierung Spam: ja/nein)\n",
    "- Wird der Kunde aufgrund seines Einkaufsverhaltens in meinem Webshop wieder bei mir einkaufen? (Klassifizierung: Wiedereinkaufen: ja/nein)\n",
    "- Chatbot: Um welches Thema geht es dem Kunden bei einer Anfrage? (Klassifizierung: z.B. Adressänderung / Beschwerde / Technisches Problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-lunch",
   "metadata": {},
   "source": [
    "# Mathematik des Naiven Bayes (NB) Klassifikators\n",
    "\n",
    "Sie müssen diesen Abschnitt nicht verstehen, aber für diejenigen, die die mathematischen Hintergründe hinter dem NB-Klassifkator interessieren, möchte ich diese auch nicht vorenthalten.\n",
    "\n",
    "Falls Sie Mathematik in der Oberstufe hatten oder Sie haben mal als Student eine Vorlesung zum Thema Wahrscheinlichkeitsrechnung besucht, dann erinnern Sie sich vielleicht noch an den *Satz von Bayes*:\n",
    "\n",
    "                P(B|A) * P(A)\n",
    "    P(A|B) =  -----------------\n",
    "                     P(B)\n",
    "\n",
    "Klingt abstrakt, oder? Die einzelnen Termine in dieser Formel haben auch Namen:\n",
    "\n",
    "* P(A|B) und P(B|A) werden *bedingte Wahrscheinlichkeiten* genannt\n",
    "* P(A) und P(B) werden *a-priori Wahrscheinlichkeiten* genannt\n",
    "* A und B werden in der Wahrscheinlichkeitsrechnung *Ereignisse* genannt\n",
    "\n",
    "Machen wir es mal konkret:\n",
    "* A soll das Ereignis sein, dass eine eingehende eMail eine Spam-eMail ist\n",
    "* B soll das Ereignis sein, dass in der eingehenden eMail das Wort \"Kaufen\" vorkommt\n",
    "\n",
    "Jetzt kommt eine neue eMail mit dem Wort \"Kaufen\" im eMail-Text rein. Ein Spam-Filter muss dann die Frage beantworten: Ist dies eine Spam-eMail?\n",
    "\n",
    "Dazu wird die bedingte Wahrscheinlichkeit P(A|B) ausgerechnet, denn das ist genau die Wahrscheinlichkeit, dass eine eingehende eMail eine Spam-eMail ist unter der Voraussetzung, dass das Wort \"Kaufen\" detektiert wurde.\n",
    "\n",
    "Der Satz von Bayes sagt uns, dass wir diese Wahrscheinlichkeit jetzt auch so ausrechnen können:\n",
    "\n",
    "* wir schätzen die a-priori Wahrscheinlichkeit P(A) ab, indem wir z.B. ausrechnen, wie häufig in einem Beispieldatensatz von eMails Spam-eMails enthalten sind\n",
    "* wir schätzen die a-priori Wahrscheinlichkeit P(B) ab, indem wir uns wieder einen Beispieldatensatz von eMails anschauen und die Anzahl von eMails zählen, in denen das Wort \"Kaufen\" vorkommt\n",
    "* wir schätzen die bedingte Wahrscheinlichkeit P(B|A) ab, indem wir in unserem Beispieldatensatz von eMails zählen, wie oft eine eMail, die definitiv eine Spam-eMail war, auch das Wort \"Kaufen\" enthielt\n",
    "\n",
    "Dann haben wir alle 3 Terme für den rechten Teil des *Satzes von Bayes* und können die Wahrscheinlichkeit, dass eine eingehende eMail mit dem Wort \"Kaufen\" eine Spam eMail ist, abschätzen.\n",
    "\n",
    "Jetzt ist eine Entscheidung, ob eine eMail eine Spam eMail ist auf Basis von nur einem Wort sicherlich nicht ratsam. Den Satz von Bayes gibt es aber auch für mehrere Ereignisse (bzw. hier: Wörter) *B1, B2, ..., Bn*:\n",
    "\n",
    "\n",
    "                            P(B1,B2, ..., Bn|A) * P(A)\n",
    "    P(A|B1,B2,....,Bn) =  ----------------------------\n",
    "                                 P(B1,B2, ..., Bn)\n",
    "                                 \n",
    "Um das Ganze formelmäßig zu vereinfachen, macht der *Naive Bayes Klassifikator* jetzt eine *naive Annahme*, die in der Welt so meistens nicht stimmt: er sagt, dass die Wörter (Merkmale) B1,B2,...,Bn unabhängig voneinander betrachtet werden können:\n",
    "\n",
    "    \n",
    "                            P(B1|A) * P(B2|A) * ... * P(Bn|A) * P(A)\n",
    "    P(A|B1,B2,....,Bn) =  ------------------------------------------\n",
    "                                       P(B1,B2, ..., Bn)\n",
    "                                       \n",
    "Außerdem hängt der Wert P(B1,B2, ..., Bn) im Nenner ja nicht von A ab, so dass der *Naive Bayes Klassifikator* \"sagt\": ob es eine Spam-eMail ist (A) oder nicht (^A) kann ich einfach entscheiden, indem ich schaue, welcher Wert größer ist:\n",
    "\n",
    "    \n",
    "                            \n",
    "    P(A=eMail ist Spam|B1,B2,....,Bn) = \n",
    "                                   c * P(B1|A)* P(B2|A) * ... * P(Bn|A) * P(A)\n",
    "    \n",
    "    oder\n",
    "    \n",
    "    P(^A=eMail ist KEIN Spam|B1,B2,....,Bn) =\n",
    "                                   c * P(B1|^A) * P(B2|^A) * ... * P(Bn|^A) * P(^A)\n",
    "\n",
    "wobei c:=1/P(B1,B2, ..., Bn) nur eine Konstante ist und daher zum Vergleich welcher Wert größer ist nicht vorliegen muss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-reservoir",
   "metadata": {},
   "source": [
    "# Wahrscheinlichkeitsverteilungen\n",
    "\n",
    "Der Kern beim *Naiven Bayes Klassifikator* ist also das Schätzen der Wahrscheinlichkeiten P(B1|A), P(B2|A), etc. Doch was hier mit lauter \"P\"s schön mathematisch korrekt beschrieben ist, muss bei einer Implementierung im Computer konkretisiert werden. Man kann zur Modellierung von Wahrscheinlichkeiten diskrete Wahrscheinlichkeitswerte nehmen, oder aber auch, eine Wahrscheinlichkeitsverteilung zugrunde legen.\n",
    "\n",
    "In scikit-learn sind es gleich mehrere Wahrscheinlichkeitsverteilungen, die sie auswählen können, z.B:\n",
    "\n",
    "* Normalverteilung (\"Gauß-Glocke\") ==> [GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "* Multinomiale Verteilung ==> [MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB)\n",
    "* Bernoulli Verteilung ==> [BernoulliNB](https://scikit-learn.org/stable/modules/naive_bayes.html#bernoulli-naive-bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-january",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
